{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YXuLIRm1TWAM",
    "outputId": "e3ae0853-0545-44b1-e2f3-4ed6d7e51b24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.5.0+cu101'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "import transformers\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import trange\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuU-_fnkeTrt"
   },
   "source": [
    "### PyTorch Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "2x4MAf0aeV9S",
    "outputId": "55803d12-905b-431e-e1b0-e61570d92d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsDu9pz_eGQC"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "hZu6I6RITvsG",
    "outputId": "61530db9-2a0b-43b8-edfb-de5bff471036"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ner_dataset.csv',\n",
    "                   encoding='latin1').fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gwtzv2HT0po"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdMWRPM_T757"
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "3T8GtEcAT9QY",
    "outputId": "e499c5f3-4fe7-4002-fb3d-24e08568d28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "HFIwdM6lWHn7",
    "outputId": "c28df83b-d700-4517-9059-1a5f91af5d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = [[s[2] for s in sentence] for sentence in getter.sentences]\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "s00vBSkAWJ_T",
    "outputId": "228ed5a6-c6a4-4920-b168-fd5c1f98757b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art': 13,\n",
       " 'B-eve': 4,\n",
       " 'B-geo': 8,\n",
       " 'B-gpe': 7,\n",
       " 'B-nat': 10,\n",
       " 'B-org': 12,\n",
       " 'B-per': 2,\n",
       " 'B-tim': 1,\n",
       " 'I-art': 14,\n",
       " 'I-eve': 0,\n",
       " 'I-geo': 16,\n",
       " 'I-gpe': 3,\n",
       " 'I-nat': 5,\n",
       " 'I-org': 9,\n",
       " 'I-per': 11,\n",
       " 'I-tim': 15,\n",
       " 'O': 6,\n",
       " 'PAD': 17}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_values = list(set(data[\"Tag\"].values))\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNeYUK8WWdXh"
   },
   "outputs": [],
   "source": [
    "## Hyperparams\n",
    "MAX_LEN = 75\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sk_DpZoeeeqB"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "va2R3eQJXftB"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JAVIv7zXnf8"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDwNnR15Xo8_"
   },
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [\n",
    "    tokenize_and_preserve_labels(sent, labs)\n",
    "    for sent, labs in zip(sentences, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQOhWnytXqA5"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omHouuZUXrld"
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                          truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ACiMAz_Xs8W"
   },
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KeuoLOYEYKoc"
   },
   "outputs": [],
   "source": [
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDhzsYfOXuHc"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
    "                                                            random_state=42069, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=42069, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFj6enhTei5A"
   },
   "source": [
    "### Data -->  Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCJnuysjYGd9"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yM-BCspeenh-"
   },
   "source": [
    "### PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlX3IU6sYMT6"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0m2kxic4eq9-"
   },
   "source": [
    "### Initializing BERT (base, cased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbH6EcH1YNeO"
   },
   "outputs": [],
   "source": [
    "model = transformers.BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CQqsx3QcYOer",
    "outputId": "177488e5-c186-49f0-c234-01b98c24d928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAwF2AccezTw"
   },
   "source": [
    "### Fine-tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg8umSgFYPwk"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0ZVCFArYQ17"
   },
   "outputs": [],
   "source": [
    "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KY81O6MlYTzx"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbmTnU4mfF8S"
   },
   "source": [
    "### Train BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "NdEz_vlBYW0E",
    "outputId": "9f7cfd28-c6cf-4744-f5c1-4a9a18e6df8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.18960450102800877\n",
      "Validation loss: 0.13779307608803112\n",
      "Validation Accuracy: 0.9574096555853054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 1/3 [06:11<12:23, 371.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.8123193641618498\n",
      "\n",
      "Average train loss: 0.10807154508510548\n",
      "Validation loss: 0.1316731454183658\n",
      "Validation Accuracy: 0.9601453493206499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 2/3 [12:23<06:11, 371.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.8288206707114613\n",
      "\n",
      "Average train loss: 0.08157335130223042\n",
      "Validation loss: 0.13179464516540368\n",
      "Validation Accuracy: 0.9622823502020589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [18:36<00:00, 372.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score: 0.8332931678515484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Store the average loss after each epoch so we can plot them.\n",
    "loss_values, validation_loss_values = [], []\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        # This will return the loss (rather than the model output)\n",
    "        # because we have provided the `labels`.\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        # get the loss\n",
    "        loss = outputs[0]\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        total_loss += loss.item()\n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    # Put the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the validation loss for this epoch.\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                            attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Move logits and labels to CPU\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    eval_loss = eval_loss / len(valid_dataloader)\n",
    "    validation_loss_values.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "    valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "    print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "WUipSaN5Ylon",
    "outputId": "453ffd05-39fe-4e0d-a18c-0762583572ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.plot(loss_values, 'b-o', label='Training loss')\n",
    "plt.plot(validation_loss_values, 'r-o', label='Validation loss')\n",
    "\n",
    "plt.title('Train v Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtNhrosGfi8w"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr2SwleVLQbP"
   },
   "outputs": [],
   "source": [
    "def ner(sentence):\n",
    "    tokenized_sentence = tokenizer.encode(sentence)\n",
    "    input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "    new_tokens, new_labels = [], []\n",
    "    for token, label_idx in zip(tokens, label_indices[0]):\n",
    "        if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[label_idx])\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t{}\".format(label, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "xmRfHU3mTBb_",
    "outputId": "b9c0eb4c-a729-4519-f85a-80a7e4174471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\t[CLS]\n",
      "B-per\tBruce\n",
      "I-per\tWayne\n",
      "O\t&\n",
      "B-per\tBarry\n",
      "I-per\tAllen\n",
      "O\tare\n",
      "O\tmembers\n",
      "O\tof\n",
      "O\tthe\n",
      "B-org\tJustice\n",
      "I-org\tLeague\n",
      "O\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\" Bruce Wayne & Barry Allen are members of the Justice League \"\"\"\n",
    "ner(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tohp3dXhTDII"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NER with BERT",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
