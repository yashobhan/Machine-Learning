{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>156728</td>\n",
       "      <td>156729</td>\n",
       "      <td>B000UXBOOI</td>\n",
       "      <td>A2ESR2RFX9EVM6</td>\n",
       "      <td>Robert Ferguson \"Bob\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1317859200</td>\n",
       "      <td>Rice Crackers - Good</td>\n",
       "      <td>I had a few of these on a road trip with a fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265199</td>\n",
       "      <td>265200</td>\n",
       "      <td>B001W3OR1W</td>\n",
       "      <td>A1SHTWE21VLJQP</td>\n",
       "      <td>C. Bedell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1252627200</td>\n",
       "      <td>Almost as good as tootsie rolls</td>\n",
       "      <td>I was diagnosed with Type 2 diabetes last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227190</td>\n",
       "      <td>227191</td>\n",
       "      <td>B002QZ5Z16</td>\n",
       "      <td>AXHAC0QW02M9N</td>\n",
       "      <td>Neil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1287792000</td>\n",
       "      <td>Fingerlicking good!!!</td>\n",
       "      <td>Had been looking for this pita for a while and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344436</td>\n",
       "      <td>344437</td>\n",
       "      <td>B0026KNQSA</td>\n",
       "      <td>AVABPJCKE2MR5</td>\n",
       "      <td>spal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1314921600</td>\n",
       "      <td>Popchips Jalapeno flavor</td>\n",
       "      <td>I bought a case of jalapeno chips as I love th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59239</td>\n",
       "      <td>59240</td>\n",
       "      <td>B0012KH06E</td>\n",
       "      <td>ACSFLABBSAP36</td>\n",
       "      <td>IAN P ONEAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1318982400</td>\n",
       "      <td>Cheaper on petco's site</td>\n",
       "      <td>only $13.29 a case on the petco site (Oct 20, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId            ProfileName  \\\n",
       "156728  156729  B000UXBOOI  A2ESR2RFX9EVM6  Robert Ferguson \"Bob\"   \n",
       "265199  265200  B001W3OR1W  A1SHTWE21VLJQP              C. Bedell   \n",
       "227190  227191  B002QZ5Z16   AXHAC0QW02M9N                   Neil   \n",
       "344436  344437  B0026KNQSA   AVABPJCKE2MR5                   spal   \n",
       "59239    59240  B0012KH06E   ACSFLABBSAP36            IAN P ONEAL   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "156728                     0                       1      4  1317859200   \n",
       "265199                     0                       0      5  1252627200   \n",
       "227190                     0                       0      5  1287792000   \n",
       "344436                     0                       0      4  1314921600   \n",
       "59239                      0                       0      1  1318982400   \n",
       "\n",
       "                                Summary  \\\n",
       "156728             Rice Crackers - Good   \n",
       "265199  Almost as good as tootsie rolls   \n",
       "227190            Fingerlicking good!!!   \n",
       "344436         Popchips Jalapeno flavor   \n",
       "59239           Cheaper on petco's site   \n",
       "\n",
       "                                                     Text  \n",
       "156728  I had a few of these on a road trip with a fri...  \n",
       "265199  I was diagnosed with Type 2 diabetes last year...  \n",
       "227190  Had been looking for this pita for a while and...  \n",
       "344436  I bought a case of jalapeno chips as I love th...  \n",
       "59239   only $13.29 a case on the petco site (Oct 20, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../Resources/data/text_summarization/fine_foods_reviews.csv')\n",
    "data = data.sample(200000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "data.drop_duplicates(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161180, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape ## Shape after dropping duplicates and NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing all datapoints from sampled data that are below a certain length\n",
    "data = data[data['Text'].str.split().apply(len) < 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42070, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {     \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"iit will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text, contractions=contractions_dict, remove_stop=False):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(' ')])\n",
    "    text = re.sub(r\"'s\\b\", \"\", text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub('[m]{2, }', 'mm', text)\n",
    "    \n",
    "    return ' '.join(text.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this am not it chief'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(\"this ain't it, chief!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>227190</td>\n",
       "      <td>had been looking for this pita for a while and...</td>\n",
       "      <td>fingerlicking good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59239</td>\n",
       "      <td>only a case on the petco site not worth the ce...</td>\n",
       "      <td>cheaper on petco site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357229</td>\n",
       "      <td>if you are looking for something natural to re...</td>\n",
       "      <td>great for hot flashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191682</td>\n",
       "      <td>it is a great thing we are using it since we g...</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348190</td>\n",
       "      <td>this food is the best our golden retriever who...</td>\n",
       "      <td>itchy scratchy golden retriever no more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "227190  had been looking for this pita for a while and...   \n",
       "59239   only a case on the petco site not worth the ce...   \n",
       "357229  if you are looking for something natural to re...   \n",
       "191682  it is a great thing we are using it since we g...   \n",
       "348190  this food is the best our golden retriever who...   \n",
       "\n",
       "                                        summary  \n",
       "227190                       fingerlicking good  \n",
       "59239                     cheaper on petco site  \n",
       "357229                    great for hot flashes  \n",
       "191682                                   yogurt  \n",
       "348190  itchy scratchy golden retriever no more  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.DataFrame()\n",
    "reviews['text'] = data['Text'].apply(clean)\n",
    "reviews['summary'] = data['Summary'].apply(clean)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>227190</td>\n",
       "      <td>had been looking for this pita for a while and...</td>\n",
       "      <td>sostok fingerlicking good eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59239</td>\n",
       "      <td>only a case on the petco site not worth the ce...</td>\n",
       "      <td>sostok cheaper on petco site eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357229</td>\n",
       "      <td>if you are looking for something natural to re...</td>\n",
       "      <td>sostok great for hot flashes eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191682</td>\n",
       "      <td>it is a great thing we are using it since we g...</td>\n",
       "      <td>sostok yogurt eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348190</td>\n",
       "      <td>this food is the best our golden retriever who...</td>\n",
       "      <td>sostok itchy scratchy golden retriever no more...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "227190  had been looking for this pita for a while and...   \n",
       "59239   only a case on the petco site not worth the ce...   \n",
       "357229  if you are looking for something natural to re...   \n",
       "191682  it is a great thing we are using it since we g...   \n",
       "348190  this food is the best our golden retriever who...   \n",
       "\n",
       "                                                  summary  \n",
       "227190                   sostok fingerlicking good eostok  \n",
       "59239                 sostok cheaper on petco site eostok  \n",
       "357229                sostok great for hot flashes eostok  \n",
       "191682                               sostok yogurt eostok  \n",
       "348190  sostok itchy scratchy golden retriever no more...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['summary'] = reviews['summary'].apply(lambda x: 'sostok ' + x + ' eostok')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Review:  had been looking for this pita for a while and found it online ordering was the best thing i ever did\n",
      "* Summary:  sostok fingerlicking good eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  only a case on the petco site not worth the cents a can they are charging here\n",
      "* Summary:  sostok cheaper on petco site eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  if you are looking for something natural to relieve hot flashes sage tea will do it a glass in the morning and one at night and wow what a difference it made\n",
      "* Summary:  sostok great for hot flashes eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  it is a great thing we are using it since we got it and every newone is better and better thanks\n",
      "* Summary:  sostok yogurt eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  this food is the best our golden retriever who is prone to all sorts of allergies is scratch free with this food thanks amazon for making it so easy to order online\n",
      "* Summary:  sostok itchy scratchy golden retriever no more eostok\n",
      "** ---- ** ---- **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('* Review: ', reviews['text'].iloc[i])\n",
    "    print('* Summary: ', reviews['summary'].iloc[i])\n",
    "    print('** ---- ** ---- **\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.DataFrame()\n",
    "lengths['text'] = [len(i.split()) for i in reviews['text']]\n",
    "lengths['summary'] = [len(i.split()) for i in reviews['summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(lengths['text'], bins=30)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(lengths['summary'], bins=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>42070.000000</td>\n",
       "      <td>42070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>25.919990</td>\n",
       "      <td>5.231828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.451605</td>\n",
       "      <td>2.038471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text       summary\n",
       "count  42070.000000  42070.000000\n",
       "mean      25.919990      5.231828\n",
       "std        5.451605      2.038471\n",
       "min        3.000000      2.000000\n",
       "25%       22.000000      4.000000\n",
       "50%       26.000000      5.000000\n",
       "75%       30.000000      6.000000\n",
       "max       64.000000     27.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = int(lengths['text'].max())\n",
    "summary_len = int(lengths['summary'].quantile(q=0.75))\n",
    "\n",
    "text_len, summary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37863,), (4207,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews['text'], reviews['summary'], test_size=0.1, shuffle=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "X_tokenizer.fit_on_texts(reviews['text'])\n",
    "\n",
    "y_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "y_tokenizer.fit_on_texts(reviews['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer.word_index['sostok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_test = y_tokenizer.texts_to_sequences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=text_len, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=text_len, padding='post')\n",
    "\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=summary_len, padding='post')\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test, maxlen=summary_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "glove_embeddings = np.load('../../Resources/glove.840B.300d.pkl', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_embeddings(emb_index, tokenizer=X_tokenizer, latent_dim=300):\n",
    "    emb_matrix = np.zeros((len(tokenizer.word_index)+1, latent_dim), dtype='float32')\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        emb_vector = emb_index.get(word)\n",
    "        if emb_vector is not None:\n",
    "            emb_matrix[i] = emb_vector\n",
    "    return emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20906, 300), (9574, 300))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings = map_embeddings(glove_embeddings)\n",
    "summary_embeddings = map_embeddings(glove_embeddings, tokenizer=y_tokenizer)\n",
    "\n",
    "text_embeddings.shape, summary_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_keras.layers.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_embeddings (Embedding)     (None, 63, 300)      6271800     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "summary_embeddings (Embedding)  (None, None, 300)    2872200     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm2 (LSTM)            [(None, 63, 500), (N 1602000     text_embeddings[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 500),  1602000     summary_embeddings[0][0]         \n",
      "                                                                 encoder_lstm2[0][1]              \n",
      "                                                                 encoder_lstm2[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      encoder_lstm2[0][0]              \n",
      "                                                                 decoder_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           decoder_lstm[0][0]               \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9574)   9583574     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 22,432,074\n",
      "Trainable params: 13,288,074\n",
      "Non-trainable params: 9,144,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## ENCODER\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(text_len, ), name='encoder_inputs')\n",
    "X_embeddings = tf.keras.layers.Embedding(len(X_tokenizer.word_index)+1, 300, \n",
    "                                              trainable=False, weights=[text_embeddings],\n",
    "                                              name='text_embeddings')\n",
    "encoder_embeddings = X_embeddings(encoder_inputs)\n",
    "\n",
    "## LSTM - 1\n",
    "encoder_lstm1 = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='encoder_lstm1')\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_embeddings)\n",
    "\n",
    "## LSTM - 2\n",
    "encoder_lstm2 = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='encoder_lstm2')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "## DECODER\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, ), name='decoder_inputs')\n",
    "y_embeddings = tf.keras.layers.Embedding(len(y_tokenizer.word_index)+1, 300, \n",
    "                                              trainable=False, weights=[summary_embeddings], \n",
    "                                              name='summary_embeddings')\n",
    "decoder_embeddings = y_embeddings(decoder_inputs)\n",
    "\n",
    "## Decoder LSTM using encoder_states as initial states\n",
    "decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_embeddings, initial_state=[state_h, state_c])\n",
    "\n",
    "\n",
    "## ATTENTION\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "\n",
    "## CONCAT\n",
    "decoder_concat = tf.keras.layers.Concatenate(axis=-1, name='concat_layer') ([decoder_outputs, attn_out])\n",
    "\n",
    "## DENSE\n",
    "decoder_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(y_tokenizer.word_index)+1, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "\n",
    "## MODEL\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Resources/models/document_summarization/init_summarizer.h5'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_name = 'init_summarizer.h5'\n",
    "model_path = '../../Resources/models/document_summarization/'\n",
    "\n",
    "final_savepath = os.path.join(model_path, model_name)\n",
    "final_savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(final_savepath),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37962 samples\n",
      "37962/37962 [==============================] - 654s 17ms/sample - loss: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26abaec3388>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trained it for around 23 epochs, the params here say 1 but there were ~21 more \n",
    "\n",
    "model.fit([X_train, y_train[:, :-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "          epochs=1, batch_size=64, callbacks=cbks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "summary_embeddings (Embedding)  (None, None, 300)    2872200     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 500),  1602000     summary_embeddings[4][0]         \n",
      "                                                                 input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 63, 500)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      input_16[0][0]                   \n",
      "                                                                 decoder_lstm[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, None, 1000)   0           decoder_lstm[4][0]               \n",
      "                                                                 attention_layer[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9574)   9583574     concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,558,274\n",
      "Trainable params: 11,686,074\n",
      "Non-trainable params: 2,872,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = tf.keras.models.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "\n",
    "## Tensors to hold states of prev timestep\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = tf.keras.layers.Input(shape=(text_len, latent_dim))\n",
    "\n",
    "## Get embeddings of decoder sequence\n",
    "decoder_embeddings_2 = y_embeddings(decoder_inputs)\n",
    "\n",
    "## Set the initial states to the states of the prev timestep\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embeddings_2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "## Attention inference\n",
    "attention_inference, attention_inference_states = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inference_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs2, attention_inference])\n",
    "\n",
    "## Softmax for prob dist\n",
    "decoder_outputs2 = decoder_dense(decoder_inference_concat)\n",
    "\n",
    "## Final decoder\n",
    "decoder_model = tf.keras.models.Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "                                      [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    ## Encode the inputs\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    ## Initialize an empty target seq of len 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    ## Set the first word of target sequence as index of sostok\n",
    "    target_seq[0, 0] = y_tokenizer.word_index['sostok']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sequence = ''\n",
    "    \n",
    "    ## Loop to predict the remaining sequence\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        ## Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = y_tokenizer.index_word[sampled_token_index]\n",
    "#         print(sampled_token)\n",
    "        \n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sequence += ' ' + sampled_token\n",
    "            \n",
    "        ## Stop condition check - if eostok is predicted of max len is reached\n",
    "        if sampled_token == 'eostok' or len(decoded_sequence.split()) >= (summary_len - 1):\n",
    "            stop_condition = True\n",
    "            \n",
    "        ## Update target sequence with currently predicted token index for next loop\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        ## Update transformer states\n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq, y_tokenizer=y_tokenizer):\n",
    "    text = ''\n",
    "    \n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != y_tokenizer.word_index['sostok'] and i != y_tokenizer.word_index['eostok']:\n",
    "            text = text + y_tokenizer.index_word[i] + ' '\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2text(input_seq, y_tokenizer=y_tokenizer):\n",
    "    text = ''\n",
    "    \n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            text = text + y_tokenizer.index_word[i] + ' '\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Review: eostok people but sostok poor is coffee taste missing great good taste jerkey orange variety fire tasty eostok drink and sampler good always \n",
      "\n",
      "* Original Summary: awful \n",
      "\n",
      "* Predicted Summary:  not very good\n",
      "\n",
      "* Review: eostok gift my not it stops great pasta water flavor i super came great love disappointed tomatoes the product big not much yuck do jack \n",
      "\n",
      "* Original Summary: great gift \n",
      "\n",
      "* Predicted Summary:  great chocolates\n",
      "\n",
      "* Review: it was than coffee cereal sostok teeth wife tea carb great lovely excellent sostok horrible everyday great plant workday not addicted eostok but sostok loves rich pear w burgers \n",
      "\n",
      "* Original Summary: my dog loves this food \n",
      "\n",
      "* Predicted Summary:  tasty and chewy\n",
      "\n",
      "* Review: coffee goodness best and candy pretty is rice nice yum mix eostok know love described powder treat chips delicious excellent flavored nice \n",
      "\n",
      "* Original Summary: awesome for breakfast \n",
      "\n",
      "* Predicted Summary:  good value\n",
      "\n",
      "* Review: of coffee find priced gift good not it noodles go mexican no pasta drink and treats good a sostok columbian rip pasta finger \n",
      "\n",
      "* Original Summary: countrytime lemonade \n",
      "\n",
      "* Predicted Summary:  great\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 15):\n",
    "    print('* Review: {}\\n'.format(seq2text(X_test[i])))\n",
    "    print('* Original Summary: {}\\n'.format(seq2summary(y_test[i])))\n",
    "    print('* Predicted Summary: {}\\n'.format(decode_sequence(X_test[i].reshape(1, text_len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(input_seq, X_tokenizer=X_tokenizer):\n",
    "    input_seq = clean(input_seq)\n",
    "    input_seq = [input_seq]\n",
    "    input_seq = X_tokenizer.texts_to_sequences(input_seq)\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=text_len, padding='post')\n",
    "    \n",
    "    return decode_sequence(input_seq.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' it works'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = \"it isn't that great, it causes problems sometimes, but for the money it charges, i can't complain\"\n",
    "summarize(input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It takes quite a while to train it, even with a subset of the data. If data size is increased and more training time is allocated, the performanace can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
