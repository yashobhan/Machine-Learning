{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>244925</td>\n",
       "      <td>244926</td>\n",
       "      <td>B001VNEDDA</td>\n",
       "      <td>A2B8SUDJGJIQCY</td>\n",
       "      <td>Ronald M. Burkhart \"Burkyii\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349136000</td>\n",
       "      <td>Quality Spices</td>\n",
       "      <td>I use a lot of various spices in my cooking an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397771</td>\n",
       "      <td>397772</td>\n",
       "      <td>B001EYUE5M</td>\n",
       "      <td>ALEABNMSVO1JI</td>\n",
       "      <td>gibble</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350172800</td>\n",
       "      <td>awesome coffee</td>\n",
       "      <td>I have enjoyed this brand of coffee for severa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277459</td>\n",
       "      <td>277460</td>\n",
       "      <td>B000VK8AVK</td>\n",
       "      <td>A1N12WODE6NBRJ</td>\n",
       "      <td>Raghav Chadha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1287360000</td>\n",
       "      <td>Too much vinegar</td>\n",
       "      <td>I bought these chips looking at its sale rank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404982</td>\n",
       "      <td>404983</td>\n",
       "      <td>B0030VJ9K8</td>\n",
       "      <td>A19SXBQWY5Y4YW</td>\n",
       "      <td>Kiersten Yost</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>Ish</td>\n",
       "      <td>I generally make all of LO's food organic from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381601</td>\n",
       "      <td>381602</td>\n",
       "      <td>B00376ZEY6</td>\n",
       "      <td>APL8F73NPX6VA</td>\n",
       "      <td>Don'tstandsoclose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329091200</td>\n",
       "      <td>BEST EVER!!</td>\n",
       "      <td>These caramels are probably the best I have ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                   ProfileName  \\\n",
       "244925  244926  B001VNEDDA  A2B8SUDJGJIQCY  Ronald M. Burkhart \"Burkyii\"   \n",
       "397771  397772  B001EYUE5M   ALEABNMSVO1JI                        gibble   \n",
       "277459  277460  B000VK8AVK  A1N12WODE6NBRJ                 Raghav Chadha   \n",
       "404982  404983  B0030VJ9K8  A19SXBQWY5Y4YW                 Kiersten Yost   \n",
       "381601  381602  B00376ZEY6   APL8F73NPX6VA             Don'tstandsoclose   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "244925                     0                       0      5  1349136000   \n",
       "397771                     0                       0      5  1350172800   \n",
       "277459                     0                       0      2  1287360000   \n",
       "404982                     5                      13      3  1290556800   \n",
       "381601                     0                       0      5  1329091200   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "244925    Quality Spices  I use a lot of various spices in my cooking an...  \n",
       "397771    awesome coffee  I have enjoyed this brand of coffee for severa...  \n",
       "277459  Too much vinegar  I bought these chips looking at its sale rank ...  \n",
       "404982               Ish  I generally make all of LO's food organic from...  \n",
       "381601       BEST EVER!!  These caramels are probably the best I have ev...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../Resources/data/text_summarization/fine_foods_reviews.csv')\n",
    "data = data.sample(200000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "data.drop_duplicates(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161201, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape ## Shape after dropping duplicates and NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing all datapoints from sampled data that are below a certain length\n",
    "data = data[data['Text'].str.split().apply(len) < 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42181, 10)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {     \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"iit will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text, contractions=contractions_dict, remove_stop=False):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(' ')])\n",
    "    text = re.sub(r\"'s\\b\", \"\", text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub('[m]{2, }', 'mm', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this am not it  chief'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(\"this ain't it, chief!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>244925</td>\n",
       "      <td>i use a lot of various spices in my cooking an...</td>\n",
       "      <td>quality spices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381601</td>\n",
       "      <td>these caramels are probably the best i have ev...</td>\n",
       "      <td>best ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267529</td>\n",
       "      <td>according to the manufacturer  these are     b...</td>\n",
       "      <td>not a true soba noodle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1126</td>\n",
       "      <td>be careful   i ordered a pack of    my invoice...</td>\n",
       "      <td>beefeaters swizzles tripe     inch pack of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244735</td>\n",
       "      <td>i love this bar and eat it every day  it is ve...</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "244925  i use a lot of various spices in my cooking an...   \n",
       "381601  these caramels are probably the best i have ev...   \n",
       "267529  according to the manufacturer  these are     b...   \n",
       "1126    be careful   i ordered a pack of    my invoice...   \n",
       "244735  i love this bar and eat it every day  it is ve...   \n",
       "\n",
       "                                           summary  \n",
       "244925                              quality spices  \n",
       "381601                                   best ever  \n",
       "267529                      not a true soba noodle  \n",
       "1126    beefeaters swizzles tripe     inch pack of  \n",
       "244735                                         too  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.DataFrame()\n",
    "reviews['text'] = data['Text'].apply(clean)\n",
    "reviews['summary'] = data['Summary'].apply(clean)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>244925</td>\n",
       "      <td>i use a lot of various spices in my cooking an...</td>\n",
       "      <td>sostok quality spices eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381601</td>\n",
       "      <td>these caramels are probably the best i have ev...</td>\n",
       "      <td>sostok best ever eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267529</td>\n",
       "      <td>according to the manufacturer  these are     b...</td>\n",
       "      <td>sostok not a true soba noodle eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1126</td>\n",
       "      <td>be careful   i ordered a pack of    my invoice...</td>\n",
       "      <td>sostok beefeaters swizzles tripe     inch pack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244735</td>\n",
       "      <td>i love this bar and eat it every day  it is ve...</td>\n",
       "      <td>sostok too eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "244925  i use a lot of various spices in my cooking an...   \n",
       "381601  these caramels are probably the best i have ev...   \n",
       "267529  according to the manufacturer  these are     b...   \n",
       "1126    be careful   i ordered a pack of    my invoice...   \n",
       "244735  i love this bar and eat it every day  it is ve...   \n",
       "\n",
       "                                                  summary  \n",
       "244925                       sostok quality spices eostok  \n",
       "381601                            sostok best ever eostok  \n",
       "267529               sostok not a true soba noodle eostok  \n",
       "1126    sostok beefeaters swizzles tripe     inch pack...  \n",
       "244735                                  sostok too eostok  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['summary'] = reviews['summary'].apply(lambda x: 'sostok ' + x + ' eostok')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Review:  i use a lot of various spices in my cooking and wanted to find a source with a quality product at a reasonable price   frontier met that discription\n",
      "* Summary:  sostok quality spices eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  these caramels are probably the best i have ever tasted  they are smooth and buttery and the sea salt accents the smooth caramel perfectly  buy these  you will not regret it\n",
      "* Summary:  sostok best ever eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  according to the manufacturer  these are     buckwheat   a classic soba noodle should be at least      preferably     buckwheat\n",
      "* Summary:  sostok not a true soba noodle eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  be careful   i ordered a pack of    my invoice says pack of    but i received only   stick\n",
      "* Summary:  sostok beefeaters swizzles tripe     inch pack of eostok\n",
      "** ---- ** ---- **\n",
      "\n",
      "* Review:  i love this bar and eat it every day  it is very healthy and  tastes great but it is priced twice as much what i paid at local supermarket\n",
      "* Summary:  sostok too eostok\n",
      "** ---- ** ---- **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('* Review: ', reviews['text'].iloc[i])\n",
    "    print('* Summary: ', reviews['summary'].iloc[i])\n",
    "    print('** ---- ** ---- **\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.DataFrame()\n",
    "lengths['text'] = [len(i.split()) for i in reviews['text']]\n",
    "lengths['summary'] = [len(i.split()) for i in reviews['summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(lengths['text'], bins=30)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(lengths['summary'], bins=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>42181.000000</td>\n",
       "      <td>42181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>25.872668</td>\n",
       "      <td>5.250516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.463069</td>\n",
       "      <td>2.056745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text       summary\n",
       "count  42181.000000  42181.000000\n",
       "mean      25.872668      5.250516\n",
       "std        5.463069      2.056745\n",
       "min        4.000000      2.000000\n",
       "25%       22.000000      4.000000\n",
       "50%       26.000000      5.000000\n",
       "75%       30.000000      6.000000\n",
       "max       63.000000     31.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 6)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = int(lengths['text'].max())\n",
    "summary_len = int(lengths['summary'].quantile(q=0.75))\n",
    "\n",
    "text_len, summary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37962,), (4219,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews['text'], reviews['summary'], test_size=0.1, shuffle=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "X_tokenizer.fit_on_texts(reviews['text'])\n",
    "\n",
    "y_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "y_tokenizer.fit_on_texts(reviews['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_index['sostok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_test = y_tokenizer.texts_to_sequences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=text_len, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=text_len, padding='post')\n",
    "\n",
    "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=summary_len, padding='post')\n",
    "y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test, maxlen=summary_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "glove_embeddings = np.load('../../Resources/glove.840B.300d.pkl', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_embeddings(emb_index, tokenizer=X_tokenizer, latent_dim=300):\n",
    "    emb_matrix = np.zeros((len(tokenizer.word_index)+1, latent_dim), dtype='float32')\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        emb_vector = emb_index.get(word)\n",
    "        if emb_vector is not None:\n",
    "            emb_matrix[i] = emb_vector\n",
    "    return emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20906, 300), (9574, 300))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings = map_embeddings(glove_embeddings)\n",
    "summary_embeddings = map_embeddings(glove_embeddings, tokenizer=y_tokenizer)\n",
    "\n",
    "text_embeddings.shape, summary_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "del glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_keras.layers.attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_embeddings (Embedding)     (None, 63, 300)      6271800     encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "summary_embeddings (Embedding)  (None, None, 300)    2872200     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm2 (LSTM)            [(None, 63, 500), (N 1602000     text_embeddings[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 500),  1602000     summary_embeddings[0][0]         \n",
      "                                                                 encoder_lstm2[0][1]              \n",
      "                                                                 encoder_lstm2[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      encoder_lstm2[0][0]              \n",
      "                                                                 decoder_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           decoder_lstm[0][0]               \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9574)   9583574     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 22,432,074\n",
      "Trainable params: 13,288,074\n",
      "Non-trainable params: 9,144,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## ENCODER\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(text_len, ), name='encoder_inputs')\n",
    "X_embeddings = tf.keras.layers.Embedding(len(X_tokenizer.word_index)+1, 300, \n",
    "                                              trainable=False, weights=[text_embeddings],\n",
    "                                              name='text_embeddings')\n",
    "encoder_embeddings = X_embeddings(encoder_inputs)\n",
    "\n",
    "## LSTM - 1\n",
    "encoder_lstm1 = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='encoder_lstm1')\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_embeddings)\n",
    "\n",
    "## LSTM - 2\n",
    "encoder_lstm2 = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='encoder_lstm2')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "## DECODER\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, ), name='decoder_inputs')\n",
    "y_embeddings = tf.keras.layers.Embedding(len(y_tokenizer.word_index)+1, 300, \n",
    "                                              trainable=False, weights=[summary_embeddings], \n",
    "                                              name='summary_embeddings')\n",
    "decoder_embeddings = y_embeddings(decoder_inputs)\n",
    "\n",
    "## Decoder LSTM using encoder_states as initial states\n",
    "decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_embeddings, initial_state=[state_h, state_c])\n",
    "\n",
    "\n",
    "## ATTENTION\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "\n",
    "## CONCAT\n",
    "decoder_concat = tf.keras.layers.Concatenate(axis=-1, name='concat_layer') ([decoder_outputs, attn_out])\n",
    "\n",
    "## DENSE\n",
    "decoder_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(y_tokenizer.word_index)+1, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat)\n",
    "\n",
    "\n",
    "## MODEL\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Resources/models/document_summarization/init_summarizer.h5'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_name = 'init_summarizer.h5'\n",
    "model_path = '../../Resources/models/document_summarization/'\n",
    "\n",
    "final_savepath = os.path.join(model_path, model_name)\n",
    "final_savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(final_savepath),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37962 samples\n",
      "37962/37962 [==============================] - 654s 17ms/sample - loss: 0.1975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26abaec3388>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trained it for around 23 epochs, the params here say 1 but there were ~21 more \n",
    "\n",
    "model.fit([X_train, y_train[:, :-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "          epochs=1, batch_size=64, callbacks=cbks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "summary_embeddings (Embedding)  (None, None, 300)    2872200     decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 500),  1602000     summary_embeddings[4][0]         \n",
      "                                                                 input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 63, 500)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      input_16[0][0]                   \n",
      "                                                                 decoder_lstm[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, None, 1000)   0           decoder_lstm[4][0]               \n",
      "                                                                 attention_layer[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9574)   9583574     concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,558,274\n",
      "Trainable params: 11,686,074\n",
      "Non-trainable params: 2,872,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = tf.keras.models.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "\n",
    "## Tensors to hold states of prev timestep\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = tf.keras.layers.Input(shape=(text_len, latent_dim))\n",
    "\n",
    "## Get embeddings of decoder sequence\n",
    "decoder_embeddings_2 = y_embeddings(decoder_inputs)\n",
    "\n",
    "## Set the initial states to the states of the prev timestep\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embeddings_2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "## Attention inference\n",
    "attention_inference, attention_inference_states = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inference_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs2, attention_inference])\n",
    "\n",
    "## Softmax for prob dist\n",
    "decoder_outputs2 = decoder_dense(decoder_inference_concat)\n",
    "\n",
    "## Final decoder\n",
    "decoder_model = tf.keras.models.Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
    "                                      [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer.index_word[0] = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    ## Encode the inputs\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    ## Initialize an empty target seq of len 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    ## Set the first word of target sequence as index of sostok\n",
    "    target_seq[0, 0] = y_tokenizer.word_index['sostok']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sequence = ''\n",
    "    \n",
    "    ## Loop to predict the remaining sequence\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        ## Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = y_tokenizer.index_word[sampled_token_index]\n",
    "#         print(sampled_token)\n",
    "        \n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sequence += ' ' + sampled_token\n",
    "            \n",
    "        ## Stop condition check - if eostok is predicted of max len is reached\n",
    "        if sampled_token == 'eostok' or len(decoded_sequence.split()) >= (summary_len - 1):\n",
    "            stop_condition = True\n",
    "            \n",
    "        ## Update target sequence with currently predicted token index for next loop\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        ## Update transformer states\n",
    "        e_h, e_c = h, c\n",
    "        \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq, y_tokenizer=y_tokenizer):\n",
    "    text = ''\n",
    "    \n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != y_tokenizer.word_index['sostok'] and i != y_tokenizer.word_index['eostok']:\n",
    "            text = text + y_tokenizer.index_word[i] + ' '\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2text(input_seq, y_tokenizer=y_tokenizer):\n",
    "    text = ''\n",
    "    \n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            text = text + y_tokenizer.index_word[i] + ' '\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Review: eostok people but sostok poor is coffee taste missing great good taste jerkey orange variety fire tasty eostok drink and sampler good always \n",
      "\n",
      "* Original Summary: awful \n",
      "\n",
      "* Predicted Summary:  not very good\n",
      "\n",
      "* Review: eostok gift my not it stops great pasta water flavor i super came great love disappointed tomatoes the product big not much yuck do jack \n",
      "\n",
      "* Original Summary: great gift \n",
      "\n",
      "* Predicted Summary:  great chocolates\n",
      "\n",
      "* Review: it was than coffee cereal sostok teeth wife tea carb great lovely excellent sostok horrible everyday great plant workday not addicted eostok but sostok loves rich pear w burgers \n",
      "\n",
      "* Original Summary: my dog loves this food \n",
      "\n",
      "* Predicted Summary:  tasty and chewy\n",
      "\n",
      "* Review: coffee goodness best and candy pretty is rice nice yum mix eostok know love described powder treat chips delicious excellent flavored nice \n",
      "\n",
      "* Original Summary: awesome for breakfast \n",
      "\n",
      "* Predicted Summary:  good value\n",
      "\n",
      "* Review: of coffee find priced gift good not it noodles go mexican no pasta drink and treats good a sostok columbian rip pasta finger \n",
      "\n",
      "* Original Summary: countrytime lemonade \n",
      "\n",
      "* Predicted Summary:  great\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 15):\n",
    "    print('* Review: {}\\n'.format(seq2text(X_test[i])))\n",
    "    print('* Original Summary: {}\\n'.format(seq2summary(y_test[i])))\n",
    "    print('* Predicted Summary: {}\\n'.format(decode_sequence(X_test[i].reshape(1, text_len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(input_seq, X_tokenizer=X_tokenizer):\n",
    "    input_seq = clean(input_seq)\n",
    "    input_seq = [input_seq]\n",
    "    input_seq = X_tokenizer.texts_to_sequences(input_seq)\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=text_len, padding='post')\n",
    "    \n",
    "    return decode_sequence(input_seq.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' it works'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = \"it isn't that great, it causes problems sometimes, but for the money it charges, i can't complain\"\n",
    "summarize(input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It takes quite a while to train it, even with a subset of the data. If data size is increased and more training time is allocated, the performanace can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
